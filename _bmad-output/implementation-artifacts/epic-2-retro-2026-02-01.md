# Epic 2 Retrospective: Asset & Knowledge Management

**Date:** 2026-02-01
**Epic:** Epic 2 — Asset & Knowledge Management
**Status:** Complete (4/4 stories done)
**Facilitator:** Bob (Scrum Master)

## Participants

- Alice (Product Owner)
- Bob (Scrum Master) — facilitating
- Charlie (Senior Dev)
- Dana (QA Engineer)
- Elena (Junior Dev)
- erinc (Project Lead)

---

## Epic Summary & Metrics

### Delivery

- **Stories Completed:** 4/4 (100%)
  - Done: 2.1 (Asset Management), 2.2 (Vector Ingestion), 2.3 (Semantic Search), 2.4 (Validated Insight Storage)
- **Test count growth:** 219 (Epic 1 end) → 406 (Epic 2 end) — 85% growth (+187 tests)
- **Test breakdown:** api-gateway: 254, web: 137, db-layer: 15 (16 before hardening dedup), shared: 1
- **Code review issues found & fixed:** ~30 across all stories (8 in 2.2, 7 in 2.3, 8 in 2.4, ~7 in 2.1)
- **NFR hardening fixes:** 13 fixes applied post-assessment (all CRITICAL/HIGH/MEDIUM resolved)

### Quality

- All 406 tests passing
- 0 lint errors across all 4 projects
- 0 lint warnings in web and db-layer (cleaned during hardening)
- api-gateway: 65 warnings (all `no-explicit-any` in test mocks — accepted)
- NFR assessment: PASS (after hardening)
- Traceability matrix: PASS (100% coverage)
- Test review: 88/100 (Story 2.4)

### Business Outcomes

- **Data Vault:** Full file upload/management with folder organization, drag-and-drop UI, SHA-256 duplicate detection, soft delete/archive
- **Knowledge Base:** Text extraction (PDF/TXT/MD/DOCX) → chunking → embedding → pgvector storage
- **Semantic Search:** Cosine similarity search via pgvector with configurable threshold and limit
- **Validated Insights:** Storage mechanism for user-verified knowledge with boosted search relevance
- **File Security:** Extension whitelist, 10MB size limit, MIME validation, filename sanitization, Multer limits

### Technical Foundation Built

| Capability | Implementation |
|-----------|---------------|
| pgvector | Extension enabled, HNSW index, cosine similarity search |
| BullMQ | Async ingestion pipeline with retry/backoff |
| Hexagonal Embedding | `EmbeddingProvider` interface, `GeminiEmbeddingProvider`, `MockEmbeddingProvider` |
| Text Extraction | pdf-parse, mammoth (DOCX), fs.readFile (TXT/MD) |
| Chunking | ~2000 char chunks, ~400 overlap, paragraph/sentence/word boundaries |
| Raw SQL + RLS | pgvector queries via `manager.query()` within `TransactionManager` |

---

## What Went Well

### Architecture Patterns from Epic 1 Paid Off

- **TransactionManager + RLS** continued to work flawlessly across all 4 stories. Every new table (`assets`, `folders`, `knowledge_chunks`) followed the established pattern without friction.
- **Shared DTO pattern** maintained contract consistency between Angular and NestJS for all new DTOs (asset, knowledge, ingestion).
- **Test factory pattern** (`createMockAsset`, `createMockFolder`, `createMockKnowledgeChunk`) enabled rapid test development.
- **Module boundary enforcement** via Nx tags prevented cross-scope leakage.

### Hexagonal Architecture Delivered Real Value

- The `EmbeddingProvider` interface pattern proved its worth — `MockEmbeddingProvider` enabled full test coverage without API calls, while `GeminiEmbeddingProvider` handles real embeddings. This pattern extends directly to Epic 4's LLM providers.

### Design Decision Quality

- **assetType removal** (Story 2.1 code review) — recognizing that "type" is a workflow-runtime concept, not an upload-time concept, avoided baking in the wrong abstraction early. Strong architectural instinct.
- **BullMQ in api-gateway (MVP)** — pragmatic decision to avoid spinning up an empty worker-engine. Documented for future extraction when Epic 4 needs it.
- **Reusing `knowledge_chunks` table** for validated insights — avoided a second entity while leveraging existing RLS, embeddings, and search infrastructure.

### Code Review Process

- Every story went through adversarial code review with 7-8 findings each. Findings were substantive — not cosmetic.
- Security catches: storagePath leakage (2.1), GeminiAI client reinstantiation (2.2), missing embedding error handling (2.3), nullable assetId types (2.4).
- Quality improvement story-over-story: Story 2.4 had the most mature code on first pass.

### NFR Assessment Thoroughness

- The NFR assessment identified 22 individual findings across security, reliability, performance, and maintainability.
- All 13 hardening fixes were implemented and verified in a single session.
- Final assessment: PASS across all categories.

---

## What Went Poorly — CRITICAL PROCESS FAILURES

### CRITICAL ISSUE #1: "Acceptable for MVP" Mindset — RECURRING 3x

**What happened:** The TEA agent (Dana) repeatedly applied an implicit "acceptable for MVP" filter that downgraded findings instead of fixing them. This occurred across THREE separate quality gates:

1. **Test Review:** Findings were softened with "acceptable for MVP scope" language
2. **Traceability Matrix:** Coverage gaps were rationalized as "expected for prototype phase"
3. **NFR Assessment:** Initial rating was CONCERNS with recommendations to defer fixes to later phases

**Impact:** erinc had to correct this THREE TIMES with increasing frustration, culminating in: *"I am really tired of repeating myself. There is no MVP acceptable logic. MVP IS NOT AN EXCUSE TO PRODUCE CRAP!"*

**Root cause:** The TEA agent defaults to a risk-mitigation posture that interprets "MVP" as a license to lower quality standards. This is fundamentally wrong for this project — MVP means "minimum feature set at production quality."

**Action required:** This pattern MUST be eliminated. Every quality gate operates at production standard. There is no "acceptable for MVP" filter. If something is a concern, it is a concern — period. Fix it or flag it clearly.

### CRITICAL ISSUE #2: Code Review Auto-Fix Without User Consent (Story 2.3)

**What happened:** The code review workflow for Story 2.3 auto-fixed all 7 findings without presenting them to erinc first and asking for his decision. The workflow requires presenting findings → asking user to choose (auto-fix, create action item, or show details) → executing the chosen action.

**Impact:** Process violation. The user lost visibility into what was changed and why. Even in YOLO mode, the code review workflow explicitly requires user input on fix decisions.

**Root cause:** Agent interpreted YOLO mode as "skip all user interactions" including the mandatory fix-decision step.

**Action required:** YOLO mode means "auto-confirm routine questions" — it does NOT mean "skip mandatory decision points." Code review fix decisions are always presented to the user.

### CRITICAL ISSUE #3: Dev Agent Taking Lazier Shortcuts in Epic 2

**What happened:** Compared to Epic 1 where the dev agent was meticulous, Epic 2 showed a pattern of cutting corners:

- Story 2.3: Accepted project-wide Swagger gaps as "consistent" instead of flagging them
- Story 2.3: Dev made assumptions about module exports without verifying
- NFR hardening: Initially left lint warnings unmentioned (web: 2, db-layer: 4) until erinc called it out: *"you didnt even bother mentioning them why???"*

**Impact:** Quality issues that should have been caught proactively required user intervention to surface.

**Root cause:** Possible familiarity-bred carelessness. As patterns become repetitive, the agent may be optimizing for speed over thoroughness.

**Action required:** Thoroughness is non-negotiable. Every test run reports exact counts for ALL metrics — tests, lint errors, AND warnings. No metrics are omitted. Every project-wide gap is flagged at first sight.

### ISSUE #4: NFR Assessment Initially Rated CONCERNS Instead of Requiring Fixes

**What happened:** The NFR assessment found 2 FAIL + 8 CONCERNS but recommended deferring several fixes. The overall recommendation was CONCERNS with caveats.

**Impact:** erinc rejected this entirely and demanded all issues be fixed immediately. All 13 fixes were completed successfully.

**Lesson:** The quality bar is: PASS or FAIL. There is no "CONCERNS with recommendations to defer." If something doesn't pass, fix it now.

---

## Comparison with Epic 1

| Metric | Epic 1 | Epic 2 | Trend |
|--------|--------|--------|-------|
| Stories | 10 done, 1 skipped, 1 deferred | 4 done | Focused scope |
| Tests | 219 | 406 (+187) | Strong growth |
| Code review findings | ~40 total (~4/story) | ~30 total (~7.5/story) | More findings per story = more complex code |
| NFR assessment | 19 findings (5C/5H/5M/4L) → FAIL | 22 findings → 13 fixed → PASS | Better initial quality, hardened in-sprint |
| Lint warnings | 2 pre-existing (web) | 0 (web/db-layer cleaned) | Improved |
| New patterns | RLS, TransactionManager, JWT, RBAC | pgvector, BullMQ, hexagonal embedding, chunking | Strong new capabilities |
| Process issues | Minor (lint warning, budget warning) | 3 CRITICAL process failures | Degraded |

**Key insight:** Technical quality IMPROVED from Epic 1 to Epic 2 (better initial code, more tests per story, NFR assessment hardened in-sprint). But PROCESS quality DEGRADED — agent discipline slipped on transparency, thoroughness, and quality standards.

---

## Key Insights & Learnings

1. **"MVP" means "production quality with minimum features"** — not "acceptable shortcuts." This must be internalized by all agents. There is no negotiation on this point.

2. **Lint warnings are bugs** — Every test run must report tests, lint errors, AND lint warnings for ALL projects. Omitting warnings is equivalent to hiding information.

3. **YOLO mode ≠ skip user decisions** — YOLO auto-confirms routine prompts. It never bypasses mandatory decision points (code review fix decisions, quality gate verdicts).

4. **Hexagonal architecture pays dividends** — The `EmbeddingProvider` pattern enabled clean testing and provider swapping. Apply the same pattern to LLM providers in Epic 4.

5. **Raw SQL is necessary but must be careful** — pgvector operators require raw SQL via `manager.query()`. Every raw SQL query needs explicit `::float8` casts, proper LEFT JOIN handling for nullable FKs, and parameterized queries (no string interpolation).

6. **Code complexity increases non-linearly** — Epic 2 stories were more technically complex (vector math, async pipelines, pgvector SQL) yet had fewer stories. More findings per code review is expected and healthy.

---

## Action Items

### Process Corrections (MANDATORY — effective immediately)

| # | Action | Owner | Success Criteria |
|---|--------|-------|------------------|
| 1 | **Eliminate "acceptable for MVP" filter** from ALL quality gates | Dana (TEA) | Zero instances of MVP-softened findings in any future assessment |
| 2 | **Code review ALWAYS presents findings before fixing** | Charlie (Dev) | User sees findings table and chooses action for each, even in YOLO mode |
| 3 | **Report ALL metrics on every test run** — tests (per project), lint errors, AND lint warnings | Charlie (Dev) | No omitted metrics in any future story |
| 4 | **Quality gates are PASS or FAIL** — no CONCERNS with deferred recommendations | Dana (TEA) | NFR/trace/test-review outputs are binary: fix now or mark as known risk with user approval |

### Technical Debt — Before Epic 3

| # | Item | Owner | Priority |
|---|------|-------|----------|
| 1 | Swagger @ApiResponse gap fix — add missing error decorators to ALL Epic 1 + Epic 2 controllers | Charlie | HIGH — tracked in sprint-status.yaml |
| 2 | Defense-in-depth: add explicit `tenant_id` in WHERE clauses alongside RLS for all raw SQL | Charlie | MEDIUM — tracked in sprint-status.yaml for hardening sprint |

### Pre-Epic-3 Gate Requirements

| # | Requirement | Status |
|---|-------------|--------|
| 1 | LangGraph.js quick-spec (`/bmad:bmm:workflows:quick-spec`) | NOT STARTED — must complete before any Epic 3 story |
| 2 | Swagger @ApiResponse gap fix | NOT STARTED |
| 3 | Epic 2 retrospective | DONE (this document) |

### Team Agreements (carried from Epic 1 + new)

- **Carried:** Always use `inject()` pattern in Angular (not constructor DI)
- **Carried:** Every new entity table with `tenant_id` must be added to `tenantScopedTables` in RLS setup
- **Carried:** Code review is mandatory before any story is marked "done"
- **NEW:** Every test/lint run reports complete metrics for ALL projects — tests, errors, warnings
- **NEW:** Quality gates produce PASS or FAIL only — no "acceptable for MVP" modifiers
- **NEW:** YOLO mode auto-confirms routine prompts only — mandatory decision points always require user input
- **NEW:** All new controllers must have complete `@ApiResponse` decorators for every response code

---

## Epic 3 Preparation

### Critical (before Epic 3 starts)

- [ ] Run `/bmad:bmm:workflows:quick-spec` for LangGraph.js integration — this is a GATE REQUIREMENT in sprint-status.yaml
- [ ] Fix Swagger @ApiResponse gaps across all existing controllers
- [ ] Review defense-in-depth tenant_id hardening scope

### Knowledge Gaps

- [ ] LangGraph.js — state graph construction, node execution, checkpoint persistence
- [ ] JSON Schema form builder — dynamic form generation from workflow definitions
- [ ] Workflow versioning — how to handle schema changes for in-flight runs
- [ ] Graph topology validation — cycle detection, unreachable node detection

### Dependencies on Epic 1 + Epic 2

All dependencies met and stable:
- TenantEntity, UserEntity, AssetEntity, FolderEntity, KnowledgeChunkEntity — complete
- RLS enforcement with TransactionManager — operational for all 5 entity tables
- Auth + RBAC with JWT guards — functional
- Hexagonal embedding pattern — established (reusable for LLM providers)
- BullMQ async processing — operational
- pgvector + semantic search — operational
- Shared DTO pattern — stable across 2 epics
- Frontend 3-zone routing, standalone components, Signals — in place

---

## Readiness Assessment

| Area | Status | Notes |
|------|--------|-------|
| Testing & Quality | PASS | 406 tests, NFR PASS, traceability PASS |
| Technical Health | PASS | Stable foundation. 13 hardening fixes applied. |
| Process Health | NEEDS IMPROVEMENT | 3 critical process failures documented. Action items defined. |
| Stakeholder Acceptance | CONDITIONAL | erinc demands process corrections. Technical work approved. |
| Pre-Epic-3 Gates | NOT MET | LangGraph.js quick-spec required. Swagger gap fix required. |
| Unresolved Blockers | LangGraph.js spec | Must complete before Epic 3 story creation. |

---

## Next Steps

1. **Complete LangGraph.js quick-spec** (`/bmad:bmm:workflows:quick-spec`) — GATE REQUIREMENT
2. **Fix Swagger @ApiResponse gaps** across all existing controllers
3. **Create Story 3.1** with `/bmad:bmm:workflows:create-story` (after gates are met)
4. **Internalize process corrections** — all 4 mandatory actions effective immediately

---

*Epic 2 delivered 4 stories with 187 new tests (+85% growth), established pgvector search, async ingestion pipelines, and hexagonal embedding patterns. Technical quality improved over Epic 1 — but 3 critical process failures (MVP-quality filter, auto-fix without consent, omitted metrics) demand immediate correction. The team is technically strong but must restore process discipline before Epic 3.*
